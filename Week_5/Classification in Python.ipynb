{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in Python\n",
    "\n",
    "**Classification** is a type of supervised learning method where you are trying to determine what category an observation falls under based on a training dataset with known classifications. \n",
    "\n",
    "A simple example of classification is determining whether an email is spam. Another more complex example is having an image classifier tell the difference between apples, oranges, and peaches.  \n",
    "\n",
    "Classification Terminology:\n",
    "* Each data point is called an **observation** also known as an **instance**\n",
    "* The prediction variables (x<sub>1</sub>, x<sub>2</sub>,...,x<sub>n</sub>) are called **features**\n",
    "* Each possible category is called a **class**\n",
    "\n",
    "In classification, the hardest part is determining the boundaries between the different classes.\n",
    "### Where do we draw the line between an apple / orange? Should we even draw a line? \n",
    "<img src=\"fruit_pic.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "And this is just two dimensions! Imagine 5, 10, 50 or more features! At more than 4 features it becomes difficult to graph out and determine the boundary. Further, not all data will be able to be easily placed into the different classes. And of course, we can have more than 2 classes as we see here. \n",
    "\n",
    "\n",
    "## K-Nearest Neighbors\n",
    "[Source](https://www.youtube.com/watch?v=UqYde-LULfs)\n",
    "** K-Nearest Neighbors (KNN)**, in the most basic and literal sense, is looking at an instance's features and comparing it with \"k\" instances closest to it. Based on where the instance is \"mapped\" relative to others and how many neighbors you look at, you can determine its class. KNN is actually special in that we can use it for both classification and regression, but we'll emphasize its use in classification. \n",
    "\n",
    "Here's classify apples and fruits using 3-Nearest Neighbors: \n",
    "<img src=\"knn_fruit_pic.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "All three nearest neighbors of the red question mark are apples, so the red question mark will be classified as an apple. For the blue question mark, it looks like a toss-up between orange or apple. If we use 3-Nearest Neighbors for the blue question mark, then the blue question mark will be classified as an orange since there are more oranges in the circle than apples. \n",
    "\n",
    "### What would we do if we had 4-Nearest neighbors and we had a tie? What would be the best way of classifying an instance then?\n",
    "\n",
    "To avoid ties in general, it's best to keep k as an odd number for problems with two classes, as well as prevent k from being a multiple of the number of classes. \n",
    "\n",
    "To calculate the nearest neighbor, we have to use the handy-dandy distance formula from middle-school! \n",
    "\n",
    "Remember this? \n",
    "<img src=\"distance.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Same formula to calculate distance! Except this works only for two features. We have to generalize this for multiple features. This distance is called the **Euclidean Distance.**\n",
    "\n",
    "<img src=\"generalized_distance.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Here we calculate the Euclidean distance between two instances: j and k. \n",
    "\n",
    "Let's move on to coding this! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "## Random Forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
